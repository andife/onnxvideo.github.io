<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>https://andife.github.io/</title><link>/</link><description></description><atom:link href="/feeds/speaker_haihao-shen-intel-china-and-saurabh-tangri-intel.rss.xml" rel="self"></atom:link><lastBuildDate>Fri, 24 Jun 2022 00:00:00 +0000</lastBuildDate><item><title>Quantization support for ONNX using Intel Neural Compressor (formerly named Intel Low Precision Optimization Tool)</title><link>/onnx-community-day-2021_03/quantization-support-for-onnx-using-intel-neural-compressor-formerly-named-intel-low-precision-optimization-tool.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Haihao Shen (Intel - China) and Saurabh Tangri (Intel)</dc:creator><pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate><guid>tag:,2022-06-24:onnx-community-day-2021_03/quantization-support-for-onnx-using-intel-neural-compressor-formerly-named-intel-low-precision-optimization-tool.html</guid></item></channel></rss>