<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>https://andife.github.io/</title><link>/</link><description></description><lastBuildDate>Fri, 24 Jun 2022 00:00:00 +0000</lastBuildDate><item><title>Quantization support for ONNX using Intel Neural Compressor (formerly named Intel Low Precision Optimization Tool)</title><link>/onnx-community-day-2021_03/quantization-support-for-onnx-using-intel-neural-compressor-formerly-named-intel-low-precision-optimization-tool.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Haihao Shen (Intel - China) and Saurabh Tangri (Intel)</dc:creator><pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:,2022-06-24:onnx-community-day-2021_03/quantization-support-for-onnx-using-intel-neural-compressor-formerly-named-intel-low-precision-optimization-tool.html</guid></item></channel></rss>